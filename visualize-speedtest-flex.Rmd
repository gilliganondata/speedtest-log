---
title: "Scheduled SpeedTest Results"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    navbar:
      - { icon: "fa-github", title: "Source code", href: "https://github.com/gilliganondata/speedtest-log/", align: right }
    css: styles.css
runtime: shiny
---

```{r setup, include=FALSE}

# The includes:
#       after_body: tracking.html
# in the YAML is to enable dropping digital analytics tracking code such as Google Analytics
# into the Shiny app. In order for this to work, a tracking.html file needs to be included
# in the working directory with the appropriate tracking script.

library(flexdashboard)
library(shiny)
library(tidyverse)
library(lubridate)
library(scales)
library(googlesheets4)

# Assumes the Google Sheet with the data has been made public (view only / with link)
gs4_deauth()

# Get the ID for the Google Sheet where the results are stored. The technique below expects this
# ID to be recorded in .Renviron more another environment file in a variable called "SPEEDTEST_GSHEET."
# Alternatively, you can just hardcode the Google Sheets ID in a variable:
# gsheet <- "1QFjCh1hqeu0UNFmXPrlLqKbzap2SkUw89TusOj2bYgM" # 2023
gsheet <- "1BNKvk4N30KgGKQ_H_BVtSW8AaxpcjNEb1QzocswlxH4" # 2025
# gsheet <- Sys.getenv("SPEEDTEST_GSHEET")

# Set the timezone for displaying the results
timezone <- "America/New_York"

# Get the data and adjust the timezone
download_data <- read_sheet(gsheet, "Download Data") %>%
      mutate(test_time = with_tz(test_time, timezone))

upload_data <- read_sheet(gsheet, "Upload Data") %>%
      mutate(test_time = with_tz(test_time, timezone))

# For faster loading, comment out the above after the data is downloaded and just
# save a local--static--file.
# saveRDS(download_data, "download_data.rds")
# saveRDS(upload_data, "upload_data.rds")
# 
# download_data <- readRDS("download_data.rds")
# upload_data <- readRDS("upload_data.rds")

# Set up theme for the time-series
theme_ts <- theme_minimal() +
  theme(plot.title.position = "plot",
        plot.subtitle = element_text(face = "italic", colour = "gray40"),
        panel.grid.major.x = element_line(),
        panel.grid.minor.x = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour = "gray40", margin = margin(0, 5, 0, 0, "pt")),
        axis.text.y = element_text(colour = "gray30", face = "bold", size = 10))

# Set up theme for the histogram based on the time-series theme
theme_hist <- theme_ts +
  theme(axis.title.x = element_text(colour = "gray40", margin = margin(5, 0, 0, 0, "pt")),
        axis.text.x = element_text(colour = "gray30", face = "bold", size = 10),
        axis.text.y = element_text(colour = "gray30", face = "plain", size = 10))

# Function to build a time-series summary of either a download or an upload test
get_plot_ts <- function(test_data, test_type = "Unspecified", time_type = "All", 
                        timespan = c(1,100) , granularity = "Hour",
                        min_max = TRUE, quartiles_2_3 = TRUE){
  
  # We're allowing the breadth of the timeframe to be adjusted. This is the "start %" and the
  # "end %," so filter the data to whatever is selected.
  start_overall <- min(test_data$test_time)
  end_overall <- max(test_data$test_time)
  time_range <- end_overall - start_overall
  
  start_filter <- start_overall + time_range * timespan[1]/100
  end_filter <- start_overall + time_range * timespan[2]/100
  
  test_data <- test_data %>% 
    filter(test_time >= start_filter & test_time <= end_filter)
  
  # Depending on whether the overall time-series or the hour-of-day time-series is being
  # built, get test_time to be an appropriate grouping variable.
  if(time_type == "All"){
    # Change the granularity of the data
    test_data$test_time <- if(granularity == "Hour"){
      round_date(test_data$test_time, unit = "hour")
    } else if(granularity == "Day"){
      floor_date(test_data$test_time, unit = "day")
    } else {
      floor_date(test_data$test_time, unit = "week", week_start = 7)
    }
  } else {
    # Round every timestamp to the nearest hour. then convert the date to 1970-01-01 (it could
    # be any day; we'll never show it) and add the hour. This will get everything grouped
    # into "hour of the day"
    test_data <- test_data %>% 
      mutate(test_time = round_date(test_time, unit = "hour")) %>% 
      mutate(test_time = ymd_hms(19700101000000) + hour(test_time) * 3600)
  }
  
  # Get summary statistics for each round of tests
  data_viz_df <- test_data %>% 
    group_by(test_time) %>% 
    summarize(bw_median = median(bw),
              bw_mean = mean(bw),  # Not used, but adding for giggles if we wanted to chat mean vs median
              bw_min = min(bw),
              bw_first_quartile = quantile(bw, .25),
              bw_third_quartile = quantile(bw, .75),
              bw_max = max(bw)) 
  
    # Get the overall median of all tests for a horizonal line
  bw_median_overall <- median(test_data$bw)
  
  # Set the date format for scale_x_date based on which plot is being built
    if(time_type == "All"){
      date_labels_format <- "%m/%d"
      title_label <- paste("The Median", test_type, "Speed Was", 
                       round(bw_median_overall,1), "Mbps")
    } else {
      date_labels_format <- "%H:%M"
      title_label <- paste("Does", tolower(test_type), "speed vary at specific points in the day?")
    }
  
  # Build the plot
  gg <- ggplot(data_viz_df, 
               aes(x = test_time, y = bw_median, 
                   ymin = bw_first_quartile, ymax = bw_third_quartile)) +
    
    # 1st and 4th quartiles
    geom_ribbon(aes(ymin = bw_min, ymax = bw_max), 
                fill = ifelse(min_max == TRUE,"gray80", NA), alpha = 0.3) +
    
    # 2nd and 3rd quartile
    geom_ribbon(fill = ifelse(quartiles_2_3 == TRUE,"gray70", NA), alpha = 0.4) +
    
    # Overall Median
    geom_hline(mapping = aes(yintercept = bw_median_overall),
               linetype = "dashed", colour = "gray60", size = 0.7) +
    # Median by Hour
    geom_line(color = "#BF5700", size = 1) +    # Hook 'em Horns!
    
    scale_x_datetime(date_breaks = if_else(time_type == "All",
                                           if_else(granularity == "Week", "1 weeks", "1 days"), 
                                           "3 hours"),
                     date_labels = date_labels_format,
                     expand = c(0,0)) +
    labs(title = title_label,
         y = paste("Median", test_type, "Speed (Mbps)")) +
    theme_ts
  
  gg
}

# Function to build a histogram of either a download or an upload test
get_plot_hist <- function(test_data, test_type = "Unspecified", timespan = c(1,100)){
  
  # We're allowing the breadth of the timeframe to be adjusted. This is the "start %" and the
  # "end %," so filter the data to whatever is selected.
  start_overall <- min(test_data$test_time)
  end_overall <- max(test_data$test_time)
  time_range <- end_overall - start_overall
  
  start_filter <- start_overall + time_range * timespan[1]/100
  end_filter <- start_overall + time_range * timespan[2]/100
  
  test_data <- test_data %>% 
    filter(test_time >= start_filter & test_time <= end_filter)
  
  # Get the overall mean of all tests a vergical line
  bw_mean <- median(test_data$bw)
  
  # Build the histogram
  gg <- ggplot(test_data, aes(x = bw)) +
    
    # The histogram itself
    geom_histogram(fill = "#BF5700", alpha = 0.7) +
    
    # Overall mean
    geom_vline(mapping = aes(xintercept = bw_mean),
               linetype = "dashed", colour = "gray60", size = 0.7) +
    scale_y_continuous(label = comma) +
    labs(title = paste("The Mean", test_type, "Speed Was", 
                       round(bw_mean, 1), "Mbps"),
         x = paste("Mean", test_type, "Speed (Mbps)"),
         y = "# of Tests") +
    theme_hist
  
  gg
}

```

Sidebar {.sidebar}
=======================================================================

Use the settings below to manipulate the data.

```{r}

# Rate at which to flag high download traffic
sliderInput("timespan", "Adjust Timeframe Start/End:",
            min = 1, max = 100, value = c(1,100), step = 1
)

# How to Break up the timeframe data
selectInput("granularity", "Timeframe Granularity", c("Hour", "Day", "Week"),
            selected = "Hour")

# Select which quartiles to show
checkboxInput("min_max", "Show Min/Max Range", value = TRUE)
checkboxInput("quartiles_2_3", "Show 2nd and 3rd Quartiles", value = TRUE)

```

Download Test Results
=======================================================================

Row
-----------------------------------------------------------------------

### Download Speed (Mbps) Over Time

```{r}

get_download_ts <- reactive({
  timespan <- input$timespan
  granularity <- input$granularity
  min_max <- input$min_max
  quartiles_2_3 <- input$quartiles_2_3
  get_plot_ts(download_data, 
              test_type = "Download",
              time_type = "All",
              timespan = timespan, 
              granularity = granularity, 
              min_max = min_max, 
              quartiles_2_3 = quartiles_2_3)
})  

output$download_ts <- renderPlot({
  get_download_ts()
})

plotOutput("download_ts")

```

Row
-----------------------------------------------------------------------

### Download Speed (Mbps) by Hour of Day

```{r}

get_download_hour <- reactive({
  timespan <- input$timespan
  granularity <- input$granularity
  min_max <- input$min_max
  quartiles_2_3 <- input$quartiles_2_3
  get_plot_ts(download_data, 
              test_type = "Download",
              time_type = "Hour of Day",
              timespan = timespan, 
              granularity = granularity, 
              min_max = min_max, 
              quartiles_2_3 = quartiles_2_3)
})  

output$download_hour <- renderPlot({
  get_download_hour()
})

plotOutput("download_hour")

```

### Distribution of Download Speeds

```{r}

get_download_hist <- reactive({
  timespan <- input$timespan
  get_plot_hist(download_data, 
              test_type = "Download",
              timespan = timespan)
})  

output$download_hist <- renderPlot({
  get_download_hist()
})

plotOutput("download_hist")

```


Upload Test Results
=======================================================================

Row
-----------------------------------------------------------------------

### Upload Speed Over Time

```{r}

get_upload_ts <- reactive({
  timespan <- input$timespan
  granularity <- input$granularity
  min_max <- input$min_max
  quartiles_2_3 <- input$quartiles_2_3
  get_plot_ts(upload_data, 
              test_type = "Upload",
              time_type = "All",
              timespan = timespan, 
              granularity = granularity, 
              min_max = min_max, 
              quartiles_2_3 = quartiles_2_3)
})  

output$upload_ts <- renderPlot({
  get_upload_ts()
})

plotOutput("upload_ts")

```

Row
-----------------------------------------------------------------------

### Upload Speed (Mbps) by Hour of Day

```{r}

get_upload_hour <- reactive({
  timespan <- input$timespan
  granularity <- input$granularity
  min_max <- input$min_max
  quartiles_2_3 <- input$quartiles_2_3
  get_plot_ts(upload_data, 
              test_type = "Upload",
              time_type = "Hour of Day",
              timespan = timespan, 
              granularity = granularity, 
              min_max = min_max, 
              quartiles_2_3 = quartiles_2_3)
})  

output$upload_hour <- renderPlot({
  get_upload_hour()
})

plotOutput("upload_hour")

```

### Distribution of Upload Speeds

```{r}

get_upload_hist <- reactive({
  timespan <- input$timespan
  get_plot_hist(upload_data, 
              test_type = "Upload",
              timespan = timespan)
})  

output$upload_hist <- renderPlot({
  get_upload_hist()
})

plotOutput("upload_hist")

```
